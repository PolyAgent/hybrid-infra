{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "# %pip install -r /content/requirments.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint as pp\n",
    "\n",
    "load_dotenv()\n",
    "print(os.environ['ZAPIER_WEBHOOK'])\n",
    "\n",
    "import jax\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_nlp\n",
    "# keras.config.set_floatx(\"float16\")\n",
    "# Model\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_7b_en\")\n",
    "# gemma_lm.preprocessor.tokenizer = keras_nlp.models.GemmaTokenizer(\n",
    "#     proto=\"/tokenizer/gemma_ua_ordered.model\"\n",
    "# )\n",
    "# gemma_lm.load_weights(\"../chkpts/weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_dev = [\n",
    "    \"\"\"Борщ це -\"\"\",\n",
    "    \"\"\"Крим - це територія\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input_prompts.txt', 'r') as file:\n",
    "    test_prompts = [line.rstrip('\\n') for line in file]\n",
    "\n",
    "def process_prompts():\n",
    "    llm_outputs = []\n",
    "    result_str = \"\"\n",
    "    for prompt in test_prompts:\n",
    "        result_str += f\"PROMPT:\\\"{prompt}\\\"\\n\"\n",
    "        output = gemma_lm.generate(prompt, max_length=96)\n",
    "        llm_outputs.append(output)\n",
    "        result_str += f\"LLM:\\n{output}\\n\\n\"\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapier snippet\n",
    "import requests\n",
    "from datetime import datetime\n",
    "webhook_url = os.environ[\"ZAPIER_WEBHOOK\"]\n",
    "model_metadata = \"blank metadata\"\n",
    "body = \"blank body\"\n",
    "def post_to_slack():\n",
    "    requests.post(webhook_url, json={'time': str(datetime.now().isoformat()), 'metadata': model_metadata, 'body': body, 'server': 'AMD mi300x'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata = f\"gemma-7b base model vanilla\"\n",
    "body = process_prompts()\n",
    "post_to_slack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_7b_en\")\n",
    "gemma_lm.preprocessor.tokenizer = keras_nlp.models.GemmaTokenizer(\n",
    "    proto=\"/tokenizer/gemma_ua_ordered.model\"\n",
    ")\n",
    "model_metadata = f\"gemma-7b base model with custom UA tokenizer\"\n",
    "body = process_prompts()\n",
    "post_to_slack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_lm.load_weights(\"/ckpts/ckpt_meaninit_full_step_260000_loss_0.99.weights.h5\")\n",
    "model_metadata = f\"gemma-7b base model with custom UA tokenizer and embd trained on 1B wiki-ua dataset\"\n",
    "body = process_prompts()\n",
    "post_to_slack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/tmp/output\"\n",
    "file_names = os.listdir(folder_path)\n",
    "print(len(file_names), sorted(file_names))\n",
    "percents = [35, 50, 70, 85, 100, 130]\n",
    "for elem in zip(percents, sorted(file_names)):\n",
    "    print(f\"{elem[0]}% of {elem[1]}\")\n",
    "    gemma_lm.load_weights(f\"/tmp/output/{elem[1]}\")\n",
    "    model_metadata = f\"{elem[0]}% of 1 epoch pretraining on 6B ua-wiki starting from trained embd\"\n",
    "    body = process_prompts()\n",
    "    post_to_slack()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
