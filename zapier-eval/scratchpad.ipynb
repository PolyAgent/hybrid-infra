{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pyenv/versions/3.10.14/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "# %pip install -r /content/requirments.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hooks.zapier.com/hooks/catch/6996241/23u9vlk/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[rocm(id=0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup environment\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint as pp\n",
    "\n",
    "load_dotenv()\n",
    "print(os.environ['ZAPIER_WEBHOOK'])\n",
    "\n",
    "import jax\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 09:51:11.069147: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors.index.json...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/task.json...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors.index.json...\n",
      "2024-07-04 09:51:12.964717: E external/xla/xla/stream_executor/rocm/rocm_driver.cc:1313] failed to allocate 181.43GiB (194814515456 bytes) from device: HIP_ERROR_OutOfMemory\n",
      "2024-07-04 09:51:12.964761: E external/xla/xla/stream_executor/rocm/rocm_driver.cc:1313] failed to allocate 163.29GiB (175333048320 bytes) from device: HIP_ERROR_OutOfMemory\n",
      "2024-07-04 09:51:12.964772: E external/xla/xla/stream_executor/rocm/rocm_driver.cc:1313] failed to allocate 146.96GiB (157799743488 bytes) from device: HIP_ERROR_OutOfMemory\n",
      "2024-07-04 09:51:12.964781: E external/xla/xla/stream_executor/rocm/rocm_driver.cc:1313] failed to allocate 132.27GiB (142019772416 bytes) from device: HIP_ERROR_OutOfMemory\n",
      "2024-07-04 09:51:12.964791: E external/xla/xla/stream_executor/rocm/rocm_driver.cc:1313] failed to allocate 119.04GiB (127817793536 bytes) from device: HIP_ERROR_OutOfMemory\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors.index.json...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/preprocessor.json...\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "import keras_nlp\n",
    "# keras.config.set_floatx(\"float16\")\n",
    "# Model\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_7b_en\")\n",
    "# gemma_lm.preprocessor.tokenizer = keras_nlp.models.GemmaTokenizer(\n",
    "#     proto=\"/tokenizer/gemma_ua_ordered.model\"\n",
    "# )\n",
    "# gemma_lm.load_weights(\"../chkpts/weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_dev = [\n",
    "    \"\"\"Борщ це -\"\"\",\n",
    "    \"\"\"Крим - це територія\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input_prompts.txt', 'r') as file:\n",
    "    test_prompts = [line.rstrip('\\n') for line in file]\n",
    "\n",
    "def process_prompts():\n",
    "    llm_outputs = []\n",
    "    result_str = \"\"\n",
    "    for prompt in test_prompts:\n",
    "        result_str += f\"PROMPT:\\\"{prompt}\\\"\\n\"\n",
    "        output = gemma_lm.generate(prompt, max_length=96)\n",
    "        llm_outputs.append(output)\n",
    "        result_str += f\"LLM:\\n{output}\\n\\n\"\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapier snippet\n",
    "import requests\n",
    "from datetime import datetime\n",
    "webhook_url = os.environ[\"ZAPIER_WEBHOOK\"]\n",
    "model_metadata = \"blank metadata\"\n",
    "body = \"blank body\"\n",
    "def post_to_slack():\n",
    "    requests.post(webhook_url, json={'time': str(datetime.now().isoformat()), 'metadata': model_metadata, 'body': body, 'server': 'AMD mi300x'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 09:51:39.330122: E tensorflow/core/util/util.cc:131] oneDNN supports DT_INT64 only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    }
   ],
   "source": [
    "model_metadata = f\"gemma-7b base model vanilla\"\n",
    "body = process_prompts()\n",
    "post_to_slack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors.index.json...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/task.json...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors.index.json...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors.index.json...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/preprocessor.json...\n"
     ]
    }
   ],
   "source": [
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_7b_en\")\n",
    "gemma_lm.preprocessor.tokenizer = keras_nlp.models.GemmaTokenizer(\n",
    "    proto=\"/tokenizer/gemma_ua_ordered.model\"\n",
    ")\n",
    "model_metadata = f\"gemma-7b base model with custom UA tokenizer\"\n",
    "body = process_prompts()\n",
    "post_to_slack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors.index.json...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/task.json...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors.index.json...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/model.safetensors.index.json...\n",
      "Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_7b_en/2/download/preprocessor.json...\n"
     ]
    }
   ],
   "source": [
    "gemma_lm.load_weights(\"/ckpts/ckpt_meaninit_full_step_260000_loss_0.99.weights.h5\")\n",
    "model_metadata = f\"gemma-7b base model with custom UA tokenizer and embd trained on 1B wiki-ua dataset\"\n",
    "body = process_prompts()\n",
    "post_to_slack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 ['ckpt_step_13200_loss_10.81.weights.h5', 'ckpt_step_19200_loss_13.06.weights.h5', 'ckpt_step_25200_loss_14.88.weights.h5', 'ckpt_step_31200_loss_15.94.weights.h5', 'ckpt_step_37200_loss_15.94.weights.h5', 'ckpt_step_48600_loss_15.94.weights.h5']\n",
      "35% of ckpt_step_13200_loss_10.81.weights.h5\n",
      "50% of ckpt_step_19200_loss_13.06.weights.h5\n",
      "70% of ckpt_step_25200_loss_14.88.weights.h5\n",
      "85% of ckpt_step_31200_loss_15.94.weights.h5\n",
      "100% of ckpt_step_37200_loss_15.94.weights.h5\n",
      "130% of ckpt_step_48600_loss_15.94.weights.h5\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/tmp/output\"\n",
    "file_names = os.listdir(folder_path)\n",
    "print(len(file_names), sorted(file_names))\n",
    "percents = [35, 50, 70, 85, 100, 130]\n",
    "for elem in zip(percents, sorted(file_names)):\n",
    "    print(f\"{elem[0]}% of {elem[1]}\")\n",
    "    gemma_lm.load_weights(f\"/tmp/output/{elem[1]}\")\n",
    "    model_metadata = f\"{elem[0]}% of 1 epoch pretraining on 6B ua-wiki starting from trained embd\"\n",
    "    body = process_prompts()\n",
    "    post_to_slack()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
